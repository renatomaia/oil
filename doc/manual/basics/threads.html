<p>Multithreading is the capacity to execute simultaneously multiple executions independently from each other.
This feature is essential in distributed systems for many reasons.
For example, threads can be used to service different clients requesting the same service independently, so they do not interfere with each other.
In this section, we present the multithreading support of OiL and how it is used.</p>

<h2>Coroutines</h2>

<p>Lua does not provide standard support for multithreading.
However, it provides the concept of coroutines, which can be used to implement a cooperative multithreading infrastructure.
Unlike preemptive multithreading, as provided by Java or POSIX Threads, the execution switch between threads does not occur automatically.
Instead the code executed by the coroutine must explicitly signal for execution switch by operation <%=link"LuaManual.coroutine.yield"%>.
For further information about Lua coroutines, see <%=link"LuaManual.Coroutines"%>.</p>

<h2>Scheduler</h2>

<p>Coroutines provide means to create independent execution threads, however it is up to the application to manage the execution of these threads.
To perform this management, OiL uses a coroutine scheduler.
The scheduler keeps a collection of all the threads of the system.
These threads are then scheduled for execution, in such way that whenever a coroutine yields its execution, the scheduler chooses another coroutine for execution following a round-robin algorithm.</p>

<p>Since the coroutine scheduler is not part of the standard virtual machine of Lua, it must be created and started by the application.
This can be done by operation <%=link("Reference.oil.main")%> that creates and initiates the execution of the scheduler with a single thread registered that executes the function <code>mainbody</code> provided as parameter.
After this operations is called, other threads can be created with operation <%=link("Reference.oil.newthread")%> that creates new coroutines to execute a function.</p>

<!--
<h2>Synchronization</h2>

<p>Cooperative multithreading is far more simple to understand and use.
For example, the implementation of synchronization mechanisms is far more simple to be implemented.
In OiL, to implement these mechanisms, we use only operations <code>oil.tasks:suspend()</code> and <code>oil.tasks:resume(thread, ...)</code> provided by the scheduler as illustrated in the example below.</p>

<p>To implement mutual exclusion between a set of cooperative threads that access a shared resource, we can use global variables or other shared memory space to indicate when a thread is using the shared resource and also to register the threads waiting for their turn to use the resource.
For example, consider the following implementation.</p>

<pre>local Mutex = { waiting = {} }
	
function Mutex:enter()
	local thread = oil.tasks.current
	if self.inside then
		self.waiting[thread] = true
		oil.tasks:suspend()
	else
		self.inside = thread
	end
end

function Mutex:leave()
	assert(self.inside == oil.tasks.current)
	local waiting = next(self.waiting)
	if waiting then
		self.waiting[waiting] = nil
		self.inside = waiting
		oil.tasks:resume(waiting)
	else
		self.inside = nil
	end
end</pre>

<p>A similar approach can be used to provide other synchronization mechanisms to common problems like <a href="http://en.wikipedia.org/wiki/Producer-consumer_problem">Producers and Consumers</a></p>
-->

<h2><a name="limitations">Limitations</a></h2>

<p>Since the thread scheduler is not integrated to the underlying operating system, any blocking system call performed by a thread will eventually suspend the execution of the application as a whole since the coroutine does not yield the execution back to the scheduler.
This is particularly true for file operations that suspend the entire execution of the application regardless of the number of other independent threads that might be ready to execute.</p>
